# ğŸ® Interactive Crawler - Quick Start Guide

## ğŸš€ What You Get:

A **fully controllable** web crawler with:
- â¸ï¸ **Pause/Resume** - Stop and restart anytime
- ğŸ“¸ **Screenshots on demand** - Capture any moment
- ğŸ’¬ **Chat interface** - Control via terminal
- ğŸ› **JavaScript debugger** - Run code in the page
- ğŸ“Š **Real-time status** - Know what's happening
- ğŸ” **Error detection** - 404s, 500s, JS errors
- ğŸŒ **Navigation control** - Go anywhere
- ğŸ–±ï¸ **Click anything** - Remote element clicking

---

## ğŸ“¦ Installation

```bash
cd /home/master/applications/hdgwrzntwa/public_html/frontend-tools

# Already installed! Just run it.
```

---

## ğŸ¯ Quick Start

### Step 1: Start the Interactive Crawler

**Terminal 1:**
```bash
cd frontend-tools

# Start the crawler (opens HTTP API on port 3000)
npm run crawl:interactive -- \
  -u pearce.stephens@gmail.com \
  -p 'fmsADMINED2013!!' \
  --port=3000
```

**What happens:**
- Logs into staff.vapeshed.co.nz
- Starts HTTP API server on port 3000
- Waits for your commands
- Captures everything automatically

### Step 2: Open the Chat Interface

**Terminal 2:**
```bash
cd frontend-tools

# Start the chat interface
npm run chat
```

**Now you can control the crawler through chat!**

---

## ğŸ’¬ Chat Commands

### Basic Commands

```
ğŸ¤– You: status
ğŸ“Š Shows current crawler state, URL, screenshot count, errors

ğŸ¤– You: pause
â¸ï¸  Pauses the crawler (it stops and waits)

ğŸ¤– You: resume
â–¶ï¸  Resumes the crawler

ğŸ¤– You: screenshot
ğŸ“¸ Captures a screenshot immediately

ğŸ¤– You: messages
ğŸ“ Shows recent log messages

ğŸ¤– You: errors
âŒ Shows all errors (404s, 500s, JS errors)
```

### Advanced Commands

```
ğŸ¤– You: eval document.title
âš™ï¸  Runs JavaScript in the page context
Returns: "Staff Portal - Dashboard"

ğŸ¤– You: go https://staff.vapeshed.co.nz/transfers
ğŸŒ Navigates to a new URL

ğŸ¤– You: click button.save-btn
ğŸ–±ï¸  Clicks the specified element

ğŸ¤– You: screenshots
ğŸ“¸ Lists all captured screenshots with paths
```

---

## ğŸŒ HTTP API Endpoints

You can also control via HTTP (useful for automation):

### Status & Control

```bash
# Get status
curl http://localhost:3000/status

# Pause
curl http://localhost:3000/pause

# Resume
curl http://localhost:3000/resume

# Stop
curl http://localhost:3000/stop
```

### Screenshots & Logs

```bash
# Capture screenshot
curl http://localhost:3000/screenshot

# Get messages
curl http://localhost:3000/messages

# Get errors
curl http://localhost:3000/errors

# List screenshots
curl http://localhost:3000/screenshots
```

### JavaScript Execution

```bash
# Run JavaScript in page context
curl -X POST http://localhost:3000/evaluate \
  -H "Content-Type: application/json" \
  -d '{"code":"document.title"}'

# Example: Get all links
curl -X POST http://localhost:3000/evaluate \
  -H "Content-Type: application/json" \
  -d '{"code":"Array.from(document.querySelectorAll(\"a\")).map(a => a.href)"}'

# Example: Check for errors on page
curl -X POST http://localhost:3000/evaluate \
  -H "Content-Type: application/json" \
  -d '{"code":"document.querySelectorAll(\".error\").length"}'
```

### Navigation & Interaction

```bash
# Navigate to URL
curl "http://localhost:3000/navigate?url=https://staff.vapeshed.co.nz/transfers"

# Click element
curl -X POST http://localhost:3000/click \
  -H "Content-Type: application/json" \
  -d '{"selector":"button.save-btn"}'
```

---

## ğŸ“Š Example Workflow

### Workflow 1: Debug a Page

**Terminal 1 (Crawler):**
```bash
npm run crawl:interactive -- -u USER -p PASS
```

**Terminal 2 (Chat):**
```
ğŸ¤– You: status
ğŸ“Š Status:
  Step: waiting_for_commands
  URL: https://staff.vapeshed.co.nz/dashboard

ğŸ¤– You: go https://staff.vapeshed.co.nz/transfers
ğŸŒ Navigating to: https://staff.vapeshed.co.nz/transfers
âœ… Navigated

ğŸ¤– You: screenshot
ğŸ“¸ Screenshot captured: manual_screenshot_1234567890.png

ğŸ¤– You: eval document.querySelectorAll('.error').length
âš™ï¸  Evaluating: document.querySelectorAll('.error').length
Result: 3

ğŸ¤– You: eval Array.from(document.querySelectorAll('.error')).map(e => e.innerText)
Result: ["Required field missing", "Invalid date format", "Duplicate entry"]

ğŸ¤– You: errors
âŒ Errors (2):
1. JavaScript Error: Cannot read property 'value' of null
2. HTTP 404: /assets/old-icon.png
```

### Workflow 2: Test Button Interactions

```
ğŸ¤– You: pause
â¸ï¸  Paused

ğŸ¤– You: screenshot
ğŸ“¸ Captured: before_click.png

ğŸ¤– You: resume
â–¶ï¸  Resumed

ğŸ¤– You: click button[data-action="save"]
ğŸ–±ï¸  Clicked: button[data-action="save"]
âœ… Clicked button[data-action="save"]

ğŸ¤– You: screenshot
ğŸ“¸ Captured: after_click.png

ğŸ¤– You: messages
ğŸ“ Recent Messages:
  [12:34:56] [ACTION] Clicking: button[data-action="save"]
  [12:34:57] [SCREENSHOT] Screenshot captured: after_click
  [12:34:57] [NETWORK] HTTP 200: /api/save-transfer
```

### Workflow 3: Find All Broken Links

```
ğŸ¤– You: eval Array.from(document.querySelectorAll('a')).map(a => ({text: a.innerText, href: a.href}))
Result: [
  {"text":"Dashboard","href":"https://staff.vapeshed.co.nz/dashboard"},
  {"text":"Transfers","href":"https://staff.vapeshed.co.nz/transfers"},
  {"text":"Old Reports","href":"https://staff.vapeshed.co.nz/old-reports"}
]

ğŸ¤– You: go https://staff.vapeshed.co.nz/old-reports
ğŸŒ Navigating...

ğŸ¤– You: errors
âŒ Errors (1):
1. HTTP 404: https://staff.vapeshed.co.nz/old-reports
```

---

## ğŸ“ Output Location

All data is saved to:
```
/home/master/applications/hdgwrzntwa/public_html/frontend-tools/reports/interactive_crawl_TIMESTAMP/
â”œâ”€â”€ messages.log              # All log messages
â”œâ”€â”€ screenshots/              # All captured screenshots
â”‚   â”œâ”€â”€ login_page_*.png
â”‚   â”œâ”€â”€ after_login_*.png
â”‚   â”œâ”€â”€ manual_screenshot_*.png
â”‚   â””â”€â”€ after_click_*.png
```

---

## ğŸ¯ Use Cases

### 1. **Debug Production Issues**
```
Start crawler â†’ Navigate to problem page â†’ 
Capture screenshot â†’ Run diagnostics â†’ 
Check console errors â†’ Test fixes live
```

### 2. **Test Form Submissions**
```
Pause before submit â†’ Inspect form data â†’ 
Screenshot â†’ Resume â†’ Submit â†’ 
Check response â†’ Verify result
```

### 3. **Find All Errors on Site**
```
Start crawler â†’ Let it run â†’ 
Check errors command â†’ 
Review 404s/500s/JS errors â†’ 
Generate report
```

### 4. **Monitor Page Changes**
```
Navigate to page â†’ Screenshot â†’ 
Wait 5 minutes â†’ Screenshot again â†’ 
Compare images â†’ Detect changes
```

### 5. **Extract Data**
```
Navigate to page â†’ 
eval Array.from(document.querySelectorAll('.product')).map(p => ({
  name: p.querySelector('.name').innerText,
  price: p.querySelector('.price').innerText
}))
â†’ Get structured data
```

---

## ğŸ’¡ Pro Tips

1. **Use `pause` before critical actions** - Lets you inspect state
2. **Always `screenshot` before/after clicks** - Visual debugging
3. **Use `eval` for quick checks** - Faster than full page load
4. **Check `errors` frequently** - Catch issues early
5. **Use `messages` to understand flow** - See what happened
6. **Save URLs in variables** - `eval window.location.href`

---

## ğŸ› Troubleshooting

**Can't connect to crawler:**
```bash
# Make sure crawler is running in Terminal 1
npm run crawl:interactive -- -u USER -p PASS
```

**Crawler stuck:**
```
ğŸ¤– You: status
# Check currentStep - might be paused

ğŸ¤– You: resume
# Try resuming
```

**Need to restart:**
```
ğŸ¤– You: stop
# Stop crawler

# Then restart in Terminal 1
npm run crawl:interactive -- -u USER -p PASS
```

---

## ğŸ“ Advanced Usage

### Custom Port

```bash
# Start on different port
npm run crawl:interactive -- -u USER -p PASS --port=4000

# Connect chat to custom port
npm run chat -- --port=4000
```

### Remote Control

```bash
# Control from another machine
npm run chat -- --host=192.168.1.100 --port=3000
```

### Automation Script

```bash
#!/bin/bash
# auto-test.sh

# Wait for login
sleep 5

# Capture initial state
curl http://localhost:3000/screenshot

# Navigate to transfers
curl "http://localhost:3000/navigate?url=https://staff.vapeshed.co.nz/transfers"

# Wait for page load
sleep 3

# Check for errors
curl http://localhost:3000/errors > errors.json

# Generate report
curl http://localhost:3000/messages > messages.json
```

---

## ğŸš€ You're Ready!

**Start crawling:**
```bash
# Terminal 1
npm run crawl:interactive -- -u USER -p PASS

# Terminal 2
npm run chat
```

**Then type:** `help` to see all commands!

ğŸ‰ **Enjoy full control over your web crawler!**
